import numpy as np
from scipy.stats import kstest, uniform, chisquare, shapiro, anderson
from statsmodels.sandbox.stats.runs import runstest_1samp 
import matplotlib.pyplot as plt
import math

### Implement Tausworthe Pseudo-Random Number Generator ###
# set r, q, l parameter values
r = 13
q = 31
l = 20

# initialize with 31 random 0's and 1's of my choosing
bin_list = [0,1,0,1,0,1,1,1,1,0,1,1,0,1,0,0,0,0,0,1,0,0,1,1,0,1,1,0,0,1,1]

# tested up to 1 million RV's and I can conclude RV's look approximately i.i.d. uniform (0, 1)
rvs = 16500

# create tausworthe generator with default bin_list above. if bin_list is specified, use that bin_list.
def tausworthe(r, q, l, rvs, bin_list=bin_list):
    length = (rvs * l) - q
    for i in range(length):
        len_bin = len(bin_list)
        if bin_list[len_bin - q] == bin_list[len_bin - r]:
            bin_list.append(0)
        else:
            bin_list.append(1)

    counter = l
    add_bits = []
    unif_list = []
    
    for i in bin_list:
        counter -= 1
        value = (2 ** counter) * i
        add_bits.append(value)
        if counter == 0:
            counter = l

    counter = l
    for i, elem in enumerate(add_bits):
        counter -= 1
        if counter == 0:
            slice_index = i + 1 - l
            value = sum(add_bits[slice_index:i+1]) / (2 ** l)
            unif_list.append(value)
            counter = l

    return unif_list

# second function just to look up the value at a specific index
def tausworthe_index(r, q, l, rvs, bin_list, index):
    return tausworthe(r, q, l, rvs, bin_list)[index]

distribution = tausworthe(r, q, l, rvs, bin_list)
print("Distribution:", distribution)

# plot histogram to see if distribution looks like it's Uniform(0, 1)
y_max = math.ceil(rvs / 20 / 100) * 100 + 200
plt.hist(distribution, 20)
plt.xlabel('X')
plt.ylabel('Count')
plt.title('Tausworthe Generator Histogram (Bin Size = 20)')
plt.axis([-.1, 1.1, 0, y_max])
plt.grid(True)
plt.show()

# plot adjacent values on a unit square
# no need to normalize bc it's already between 0 and 1

plt.scatter(distribution[:-1], distribution[1:])
plt.xlabel('U_i')
plt.ylabel('U_i+1')
plt.title('Adjacent PRNs Plotted on Unit Square')
plt.axis([-0.1, 1.1, -0.1, 1.1])
plt.grid(True)
plt.show()

# plot adjacent values on a unit cube
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')

ax.scatter(distribution[:-2], distribution[1:-1], distribution[2:])
ax.set_xlabel('U_i')
ax.set_ylabel('U_i+1')
ax.set_zlabel('U_i+2')
ax.set_title('Adjacent PRNs Plotted on Unit Cube')
plt.show()

# set level of significance (alpha)
level_of_signif = 0.05

# statistical tests on the generator to see if it returns PRN's that are approximately i.i.d. Uniform(0, 1)
# chi-squared goodness of fit test
taus_vals, bins = np.histogram(distribution, bins=20)
expected = len(distribution) / 20
chi2, pval = chisquare(taus_vals, f_exp=np.full_like(taus_vals, expected))

if pval > level_of_signif:
    print("The p-value generated from the chi-squared test for uniformity of", pval, "indicates that the PRN's are approximately uniform.")
else:
    print("The p-value generated from the chi-squared test for uniformity of", pval, "indicates that the PRN's are NOT approximately uniform.")

# Kolmogorov-Smirnov uniformity test
ks, pval = kstest(distribution, 'uniform')

if pval > level_of_signif:
    print("The p-value generated from the Kolmogorov-Smirnov test for uniformity of", pval, "indicates that the PRN's are approximately uniform.")
else:
    print("The p-value generated from the Kolmogorov-Smirnov test for uniformity of", pval, "indicates that the PRN's are NOT approximately uniform.")

# runs test for independence
rt, pval = runstest_1samp(distribution, correction=False)

if pval > level_of_signif:
    print("The p-value generated from the runs test for independence of", pval, "indicates that the PRN's are approximately independent.")
else:
    print("The p-value generated from the runs test for independence of", pval, "indicates that the PRN's are NOT approximately independent.")


# creating Normal(0,1) distributions using Uniform(0,1) distributions generated by my Tausworthe generator
# need to make sure all of the bin_list's do not generate 0's 20 times in a row or else you can't do box-muller transformation on them
bin_list2 = [1,1,1,1,1,0,0,0,1,1,0,0,1,1,1,0,0,1,1,1,0,0,1,0,0,1,0,1,0,1,0]
distribution2 = tausworthe(r, q, l, rvs, bin_list2)
distribution2 = [float(x) for x in distribution2]
distribution = np.array(distribution)
distribution2 = np.array(distribution2)

Z1 = np.sqrt(-2 * np.log(distribution)) * np.cos(2 * np.pi * distribution2)
Z2 = np.sqrt(-2 * np.log(distribution)) * np.sin(2 * np.pi * distribution2)

bin_list3 = [1,1,1,1,0,0,0,1,1,0,1,1,1,0,1,1,0,1,1,1,0,1,0,0,1,0,0,1,1,1,0]
distribution3 = tausworthe(r, q, l, rvs, bin_list3)

bin_list4 = [1,0,0,1,1,0,1,0,0,0,0,0,0,1,1,0,0,0,1,0,1,1,1,0,1,0,1,1,0,0,0]
distribution4 = tausworthe(r, q, l, rvs, bin_list4)
distribution3 = np.array(distribution3)
distribution4 = np.array(distribution4)

Z3 = np.sqrt(-2 * np.log(distribution3)) * np.cos(2 * np.pi * distribution4)
Z4 = np.sqrt(-2 * np.log(distribution3)) * np.sin(2 * np.pi * distribution4)

plt.hist(Z1, bins=20, density=True, alpha=0.5, color='b') 
plt.xlabel('X')
plt.ylabel('Count')
plt.title('Z1 Normal Distribution Histogram (Bin Size = 20)')
plt.grid(True)
plt.show()

plt.hist(Z2, bins=20, density=True, alpha=0.5, color='g') 
plt.xlabel('X')
plt.ylabel('Count')
plt.title('Z2 Normal Distribution Histogram (Bin Size = 20)')
plt.grid(True)
plt.show()

plt.hist(Z3, bins=20, density=True, alpha=0.5, color='r') 
plt.xlabel('X')
plt.ylabel('Count')
plt.title('Z3 Normal Distribution Histogram (Bin Size = 20)')
plt.grid(True)
plt.show()

plt.hist(Z4, bins=20, density=True, alpha=0.5, color='purple') 
plt.xlabel('X')
plt.ylabel('Count')
plt.title('Z4 Normal Distribution Histogram (Bin Size = 20)')
plt.grid(True)
plt.show()

# anderson-darling test is good for bigger values of n.
ad = anderson(Z1)
if ad.statistic < ad.critical_values[2]:
    print("The anderson-darling test indicates that Z1 is approximately normal.")
else:
    print("The anderson-darling test indicates that Z1 is NOT approximately normal.")

ad = anderson(Z2)
if ad.statistic < ad.critical_values[2]:
    print("The anderson-darling test indicates that Z2 is approximately normal.")
else:
    print("The anderson-darling test indicates that Z2 is NOT approximately normal.")

ad = anderson(Z3)
if ad.statistic < ad.critical_values[2]:
    print("The anderson-darling test indicates that Z3 is approximately normal.")
else:
    print("The anderson-darling test indicates that Z3 is NOT approximately normal.")

ad = anderson(Z4)
if ad.statistic < ad.critical_values[2]:
    print("The anderson-darling test indicates that Z4 is approximately normal.")
else:
    print("The anderson-darling test indicates that Z4 is NOT approximately normal.")



